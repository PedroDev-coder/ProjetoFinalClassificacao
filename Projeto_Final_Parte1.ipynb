{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPYbAuK8y4eM3rwgJbJNbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroDev-coder/ProjetoFinalClassificacao/blob/main/Projeto_Final_Parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classificação"
      ],
      "metadata": {
        "id": "UO8WoF05vv2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregar a base de dados - 'Dots' seaborn"
      ],
      "metadata": {
        "id": "f_hY8TZ-j-1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVVgXwUIj6E9"
      },
      "outputs": [],
      "source": [
        "from seaborn import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/dots.csv\"\n",
        "\n",
        "#dataset = load_dataset('dots') #Carrega o dataset\n",
        "\n",
        "dataset = pd.read_csv(url)\n",
        "\n",
        "dataset # Mostra o dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Detalhes do dataset\n",
        "\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "HYOHKX81oyQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tratamento"
      ],
      "metadata": {
        "id": "VFy_2yQtqcI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = dataset['align'] #Extrai a primeira coluna, que é o label\n",
        "\n",
        "X = dataset.drop('align',axis=1) #Dataset com a label dropado"
      ],
      "metadata": {
        "id": "-ctwoVDro3pT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "#convertendo o label (target) para valores Numéricos\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "Y = label_encoder.fit_transform(Y)\n",
        "\n",
        "column = ['align']\n",
        "\n",
        "Y = pd.DataFrame(data = Y, columns = column)\n",
        "\n",
        "Y #Mostra o target"
      ],
      "metadata": {
        "id": "eWWWlj_vuJ8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape) #(848, 1)\n",
        "print(X.shape) #(848, 4)"
      ],
      "metadata": {
        "id": "b3qOV6q2lBmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y #Mostra o target"
      ],
      "metadata": {
        "id": "k1wbPjBLlFaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X #Mostra as features"
      ],
      "metadata": {
        "id": "K_RuwQunlH2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# convertendo as features para valores Numéricos\n",
        "\n",
        "column_transformer = make_column_transformer((OneHotEncoder(), ['choice']), remainder='passthrough')\n",
        "\n",
        "X = column_transformer.fit_transform(X)\n",
        "\n",
        "columns_names = ['choice_T1', 'choice_T2', 'time', 'coherence', 'firing_rate']\n",
        "\n",
        "X = pd.DataFrame(data = X, columns = columns_names)\n",
        "\n",
        "X #Mostra as features"
      ],
      "metadata": {
        "id": "ykowWDrRZpAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dados para gerar os gráficos\n",
        "\n",
        "Tabela = Y.join(X)\n",
        "\n",
        "Tabela"
      ],
      "metadata": {
        "id": "X71mZPgY-YAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalização"
      ],
      "metadata": {
        "id": "3Wp3OC-Ht-8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Normalizando todo X\n",
        "\n",
        "X['time'] = MinMaxScaler().fit_transform(np.array(dataset['time']).reshape(-1,1))\n",
        "X['coherence'] = MinMaxScaler().fit_transform(np.array(dataset['coherence']).reshape(-1,1))\n",
        "X['firing_rate'] = MinMaxScaler().fit_transform(np.array(dataset['firing_rate']).reshape(-1,1))\n",
        "\n",
        "# Outra Forma de Normalizar\n",
        "\n",
        "#df = X.values\n",
        "#min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#x_scaled = min_max_scaler.fit_transform(df)\n",
        "#X = pd.DataFrame(x_scaled)"
      ],
      "metadata": {
        "id": "Jx-M0GLykoxT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X #Mostra os valores das features normalizadas"
      ],
      "metadata": {
        "id": "VUHUwny-lSsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinamento"
      ],
      "metadata": {
        "id": "fiEtUEX5Bwun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "show1 = [] #Decision tree 1\n",
        "show2 = [] #Decision tree 2\n",
        "\n",
        "show3 = [] #K-nearest neighbors 1\n",
        "show4 = [] #K-nearest neighbors 2\n",
        "\n",
        "show5 = [] #MLP\n",
        "show6 = [] #MLP\n",
        "\n",
        "show7 = [] #SVM\n",
        "show8 = [] #SVM\n",
        "\n",
        "show9 = [] #Random Forest\n",
        "show10 = [] #GradienteBoosting\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y) # 80% treino e 20% teste\n",
        "\n",
        "\n",
        "  # DecisionTree's\n",
        "\n",
        "  model1 = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  model2 = DecisionTreeClassifier(criterion=\"gini\", max_depth=2)\n",
        "\n",
        "  model1 = model1.fit(X_train, Y_train)\n",
        "  model2 = model2.fit(X_train, Y_train)\n",
        "\n",
        "  result1 = model1.predict(X_test)\n",
        "  result2 = model2.predict(X_test)\n",
        "\n",
        "  acc1 = metrics.accuracy_score(result1, Y_test)\n",
        "  acc2 = metrics.accuracy_score(result2, Y_test)\n",
        "\n",
        "  show1.append(round(acc1 * 100))\n",
        "  show2.append(round(acc2 * 100))\n",
        "\n",
        "  # KNeighbors\n",
        "\n",
        "  model3 = KNeighborsClassifier(n_neighbors=3, metric='euclidean', algorithm='brute')\n",
        "  model4 = KNeighborsClassifier(n_neighbors=5, metric='minkowski', algorithm='auto')\n",
        "\n",
        "  model3 = model3.fit(X_train, Y_train)\n",
        "  model4 = model4.fit(X_train, Y_train)\n",
        "\n",
        "  result3 = model3.predict(X_test)\n",
        "  result4 = model4.predict(X_test)\n",
        "\n",
        "  acc3 = metrics.accuracy_score(result3, Y_test)\n",
        "  acc4 = metrics.accuracy_score(result4, Y_test)\n",
        "\n",
        "  show3.append(round(acc3 * 100))\n",
        "  show4.append(round(acc4 * 100))\n",
        "\n",
        "  # MLP's\n",
        "\n",
        "  model5 = MLPClassifier(hidden_layer_sizes=(15,10), activation='tanh',max_iter=5000)\n",
        "  model6 = MLPClassifier(hidden_layer_sizes=(5,5), activation='relu',max_iter=5000)\n",
        "\n",
        "  model5 = model5.fit(X_train, Y_train)\n",
        "  model6 = model6.fit(X_train, Y_train)\n",
        "\n",
        "  result5 = model5.predict(X_test)\n",
        "  result6 = model6.predict(X_test)\n",
        "\n",
        "  acc5 = metrics.accuracy_score(result5, Y_test)\n",
        "  acc6 = metrics.accuracy_score(result6, Y_test)\n",
        "\n",
        "  show5.append(round(acc5 * 100))\n",
        "  show6.append(round(acc6 * 100))\n",
        "\n",
        "  #SVM's\n",
        "\n",
        "  model7 = SVC(C= 1, kernel= 'rbf', gamma= 'scale')\n",
        "  model8 = SVC(C= 1.0, kernel= 'poly', gamma= 'auto')\n",
        "\n",
        "  model7 = model7.fit(X_train, Y_train)\n",
        "  model8 = model8.fit(X_train, Y_train)\n",
        "\n",
        "  result7 = model7.predict(X_test)\n",
        "  result8 = model8.predict(X_test)\n",
        "\n",
        "  acc7 = metrics.accuracy_score(result7, Y_test)\n",
        "  acc8 = metrics.accuracy_score(result8, Y_test)\n",
        "\n",
        "  show7.append(round(acc7 * 100))\n",
        "  show8.append(round(acc8 * 100))\n",
        "\n",
        "  #Random Forest\n",
        "\n",
        "  model9 = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None)\n",
        "  model9.fit(X_train, Y_train)\n",
        "\n",
        "  result9 = model9.predict(X_test)\n",
        "\n",
        "  acc9 = metrics.accuracy_score(result9, Y_test)\n",
        "\n",
        "  show9.append(round(acc9 * 100))\n",
        "\n",
        "  #Gradient Boosting\n",
        "\n",
        "  model10 = GradientBoostingClassifier()\n",
        "  model10.fit(X_train, Y_train)\n",
        "\n",
        "  result10 = model10.predict(X_test)\n",
        "\n",
        "  acc10 = metrics.accuracy_score(result10, Y_test)\n",
        "\n",
        "  show10.append(round(acc10 * 100))"
      ],
      "metadata": {
        "id": "CGJjT_oZuRTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gráficos"
      ],
      "metadata": {
        "id": "MsRDstG6BKS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns # API de visualização\n",
        "\n",
        "train_dataset = Tabela.sample(frac=0.8,random_state=0)\n",
        "\n",
        "sns.pairplot(train_dataset[['align', 'choice_T1', 'choice_T2', 'time', 'coherence', 'firing_rate']], diag_kind=\"kde\", hue= 'align')\n",
        "\n",
        "#ou\n",
        "\n",
        "#sns.pairplot(Tabela, hue=\"align\")"
      ],
      "metadata": {
        "id": "IUxz46Nt8iMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x = \"choice\", y = \"coherence\", data = dataset, hue = \"align\")"
      ],
      "metadata": {
        "id": "iGJNseYjNtcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot( x = \"coherence\", y = \"time\", data = dataset, hue = \"align\")"
      ],
      "metadata": {
        "id": "Q0E78mYDNyje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resultados"
      ],
      "metadata": {
        "id": "EstH0JYpCIrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados\n",
        "\n",
        "print(\"========== TREEs ==========\")\n",
        "\n",
        "media1 = sum(show1) / len(show1)\n",
        "print(\"\\nTree entropy {:.3f}%\".format(media1))\n",
        "media2 = sum(show2) / len(show2)\n",
        "print(\"Tree gini {:.3f}%\\n\".format(media2))\n",
        "\n",
        "print(\"========== KNNs ===========\")\n",
        "\n",
        "media3 = sum(show3) / len(show3)\n",
        "print(\"\\nKNN euclidean {:.3f}%\".format(media3))\n",
        "media4 = sum(show4) / len(show4)\n",
        "print(\"KNN minkowski {:.3f}%\\n\".format(media4))\n",
        "\n",
        "print(\"========== MLPs ===========\")\n",
        "\n",
        "media5 = sum(show5) / len(show5)\n",
        "print(\"\\nMLP1 tanh {:.3f}%\".format(media5))\n",
        "media6 = sum(show6) / len(show6)\n",
        "print(\"MLP2 relu {:.3f}%\\n\".format(media6))\n",
        "\n",
        "print(\"========== SVCs ===========\")\n",
        "\n",
        "media7 = sum(show7) / len(show7)\n",
        "print(\"\\nSVC1 {:.3f}%\".format(media7))\n",
        "media8 = sum(show8) / len(show8)\n",
        "print(\"SVC2 {:.3f}%\\n\".format(media8))\n",
        "\n",
        "print(\"====== RandomForest =======\")\n",
        "\n",
        "media9 = sum(show9) / len(show9)\n",
        "print(\"\\nRandomForest: {:.3f}%\\n\".format(media9))\n",
        "\n",
        "print(\"===== GradientBoosting ======\")\n",
        "\n",
        "media10 = sum(show10) / len(show10)\n",
        "print(\"\\nGradientBoosting: {:.3f}%\".format(media10))\n",
        "\n",
        "#print(list(show1))\n",
        "#print(list(show1))"
      ],
      "metadata": {
        "id": "yxGeEJj1xuCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}